climate_data_fusion_pipeline is a workflow with execution model batch and topology pattern fan_out_fan_in. Its purpose is: Download and normalize weather station data from 5 meteorological agencies, then merge into unified climate dataset.

Scheduling: schedule type is cron, expression is @daily, start date is 2024-01-01, catchup/backfill is False. Control flow includes dependencies such as: download_noaa→normalize_noaa; download_ecmwf→normalize_ecmwf; download_jma→normalize_jma; download_metoffice→normalize_metoffice; download_bom→normalize_bom; normalize_noaa→merge_climate_data; normalize_ecmwf→merge_climate_data; normalize_jma→merge_climate_data; normalize_metoffice→merge_climate_data; normalize_bom→merge_climate_data.

download_noaa performs Download NOAA weather station CSV data using mechanism python_callable. download_ecmwf performs Download ECMWF weather station CSV data using mechanism python_callable. download_jma performs Download JMA weather station CSV data using mechanism python_callable. download_metoffice performs Download MetOffice weather station CSV data using mechanism python_callable. download_bom performs Download BOM weather station CSV data using mechanism python_callable. normalize_noaa performs Normalize NOAA data to standard format using mechanism python_callable. normalize_ecmwf performs Normalize ECMWF data to standard format using mechanism python_callable. normalize_jma performs Normalize JMA data to standard format using mechanism python_callable. normalize_metoffice performs Normalize MetOffice data to standard format using mechanism python_callable. normalize_bom performs Normalize BOM data to standard format using mechanism python_callable. merge_climate_data performs Merge all normalized climate data into unified dataset using mechanism python_callable.
