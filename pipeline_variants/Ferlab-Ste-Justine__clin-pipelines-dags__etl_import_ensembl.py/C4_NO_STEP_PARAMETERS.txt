Pipeline Summary:
- Pipeline ID: Ferlab-Ste-Justine__clin-pipelines-dags__etl_import_ensembl.py
- Name: etl_import_ensembl
- Purpose: ETL pipeline for importing Ensembl genomic data from FTP to object storage and processing with Spark
- Execution model: batch
- Topology pattern: linear
- Business domain: genomics
- Notes: Downloads Ensembl mapping files from FTP, checks for new versions, uploads to object storage, then processes with Spark

Control Flow:
- Dependencies (directed edges):
  - file -> table

Data Artifacts / I-O Identifiers:
- file: Homo_sapiens.GRCh38.{version}.canonical.tsv.gz (Ensembl canonical mapping file)
- file: Homo_sapiens.GRCh38.{version}.ena.tsv.gz (Ensembl ENA mapping file)
- file: Homo_sapiens.GRCh38.{version}.entrez.tsv.gz (Ensembl Entrez mapping file)
- file: Homo_sapiens.GRCh38.{version}.refseq.tsv.gz (Ensembl RefSeq mapping file)
- file: Homo_sapiens.GRCh38.{version}.uniprot.tsv.gz (Ensembl UniProt mapping file)
- file: CHECKSUMS (MD5 checksums file for Ensembl downloads)
- table: ensembl_mapping (Processed Ensembl mapping table)
- bucket: raw/landing/ensembl/ (S3 path for raw Ensembl files)

External Systems:
- http_api: Ensembl FTP (ftp.ensembl.org)
- object_storage: S3-compatible storage (cqgc-{env}-app-datalake)
- cloud_service: Kubernetes (ETL context)

Pipeline Steps:
1. file — file
  - Objective: Download Ensembl mapping files from FTP, check for new versions, and upload to object storage
  - Mechanism: python_callable
  - Inputs: url:http://ftp.ensembl.org/pub/current_tsv/homo_sapiens, file:CHECKSUMS
  - Outputs: file:Homo_sapiens.GRCh38.{version}.{type}.tsv.gz, bucket_object:raw/landing/ensembl/Homo_sapiens.GRCh38.{type}.tsv.gz
2. table — table
  - Objective: Process Ensembl mapping files with Spark and load into structured table
  - Mechanism: spark_job
  - Inputs: bucket_object:raw/landing/ensembl/Homo_sapiens.GRCh38.{type}.tsv.gz
  - Outputs: table:ensembl_mapping

Scheduling:
- Schedule type: manual
- Start date: 2022-01-01
